name: Linda Cars Weekly Scraper

on:
  schedule:
    - cron: '0 6 * * 1'  # Every Monday at 6:00 AM UTC (10:00 AM Dubai time)
  workflow_dispatch:      # Allows manual trigger from the Actions tab

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor -o /usr/share/keyrings/google-chrome.gpg
          echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-chrome.gpg] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          sudo rm -f /usr/bin/chromedriver

      - name: Install Python dependencies
        run: |
          pip install selenium webdriver-manager pandas

      - name: Restore previous scrape data
        uses: actions/cache@v4
        with:
          path: scraper/Linda Cars ad
          key: linda-data-${{ github.run_number }}
          restore-keys: |
            linda-data-

      - name: Run scraper
        env:
          EMAIL_SENDER: ${{ secrets.EMAIL_SENDER }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
        run: |
          cd scraper
          python linda_scraper.py

      - name: Upload CSV as artifact
        uses: actions/upload-artifact@v4
        with:
          name: linda-report-${{ github.run_id }}
          path: scraper/Linda Cars ad/*.csv
          retention-days: 90
